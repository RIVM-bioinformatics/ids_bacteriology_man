---
title: "Bioinformatics Pipelines for Bacteriology (IDS, RIVM)"
author: "Alejandra Hernandez-Segura, Roxanne Wolthuis"
date: "`r Sys.Date()`"
biblio-style: apalike
link-citations: yes
colorlinks: yes
lot: no
lof: no
graphics: yes
urlcolor: blue
geometry: "left=1.5in, right=1.5in, top=1.25in, bottom=1.25in"
always_allow_html: yes  
---

```{r}

knitr::opts_chunk$set(echo = TRUE, 
                      eval = FALSE,
                      error = FALSE,
                      message = FALSE,
                      warning = FALSE)
```


# Introduction and General Instructions

In this guide you will find the manuals of all the available pipelines for the Bacteriology and Parasitology Department of the IDS (RIVM). This guide is in continuous development, For additions and adjustments to this guide contact [Roxanne Wolthuis](roxanne.wolthuis@rivm.nl).

**Note:** This guide was written exclusively for users working at the RIVM, in specific the IDS department. If you are an external user it is necessary to adjust the parameters or scripts from the pipelines. Detailed information about the pipelines and parameters can be found in the repositories of each pipeline. All developed pipelines are available at the RIVM [Github](https://github.com/RIVM-bioinformatics). Please keep in mind that the main goal for our pipelines is to automate processes for the RIVM. This means we cannot give the personalized and fast-responding help that we give to users from the RIVM. If you have a question or need help please write an Issue in the corresponding GitHub repository and we will try to help as soon as possible.

## General Instructions for all pipelines {#general-instructions}

### Requirements and preparation

This handbook assumes that you are working at the “bioinformatica” environment at the RIVM. It is possible to run the pipeline in other settings and even on your laptop but you need extra steps that will not be enlisted here.  

- Placing of the data: Your data should all be placed in one single folder (no subfolders) in the BioGrid (`/data/BioGrid/<my_folder>/<my_data>/`) or in the scratch_dir folder (`/mnt/scratch_dir/<my_folder>/<my_data>/`). I strongly advice you to place it in the `scratch_dir` folder and to only copy it later to the BioGrid after the analysis. The run will be faster and therefore you will block the cluster less time for everyone else.  

- Make sure that the folder that you use as input (it contains your input data) has the right name. This means: the folder that contains your data can have any name you want provided that you only use letters, numbers or underscores. If your folder name contains different characters, it may not be recognized by the pipeline. **IMPORTANT:** Your folder name and the PATH to it (so all the folders and subfolders that you have to enter to reach your folder) should NOT CONTAIN SPACES!!!!  

- Make sure that your files have the right format: if they are fastq files, they should have the extension (`.fastq`, `.fq`, `.fastq.gz` or `.fq.gz`). If they are fasta files, they should have the extension `.fasta`. Any other requirements in the input files will be specified in the section of that specific pipeline.  

### Downloading pipelines {#downloading-instructions}

All the bacteriology pipelines created by the IDS-bioinformatics group are stored in either [GitHub](https://github.com/RIVM-bioinformatics) or the [internal GitLab](https://gitl01-int-p.rivm.nl/) of the RIVM. Only people who belong to the RIVM and that are inside one of our servers/environments can access to the later one with their normal RIVM login details.  

If you are going to download a pipeline, please do so in the same partition that your data is (preferentially `scratch_dir`). Each pipeline handbook has the instructions on where to find the code (either GitHub or GitLab). You can download every pipeline through the website or through the command line:  

_GitHub website_  

1. Go to the website for the pipeline (check the section of the specific pipeline).  
2. Press the green button “Code” on the page and then click on “Download zip” (see [Figure 1.1](#github-fig) for explanation).  
3. A zip file (<pipeline_name>-master.zip) will have likely be downloaded on your “Downloads” folder. Please move this zip file to the `BioGrid` or the `scratch_dir` partitions, depending on where your data is.  
4. Extract the files of the zip file. In Linux this is normally done by pressing the left button of the mouse, then “Open with Archive Manager” and then press “Extract” on the two windows that will consecutively appear. You could then delete the zip file (see [Figure 1.2](#extract-fig) for explanation).   

```{r github-fig, echo = FALSE, eval = TRUE, fig.cap = "Pipelines can be downloaded directly from their GitHub website."}
knitr::include_graphics("figures/screenshot_download_github.png")
```

```{r extract-fig, echo = FALSE, eval = TRUE, fig.cap = "Unzipping a repository in Linux."}
knitr::include_graphics("figures/screenshot_unzip.png")
```

_GitLab website_  

1. Go to the website for the pipeline (check the section of the specific pipeline).   
2. Press the small white button with a cloud and a downwards arrow. In the drop-down menu, choose "Download zip" (see [Figure 1.3](#gitlab-fig) for explanation).   
3. A zip file (<pipeline_name>-master.zip) will have likely be downloaded on your “Downloads” folder. Please move this zip file to the `BioGrid` or the `scratch_dir` partitions, depending on where your data is.  
4. Extract the files of the zip file. In Linux this is normally done by pressing the left button of the mouse, then “Open with Archive Manager” and then press “Extract” on the two windows that will consecutively appear. You could then delete the zip file (see [Figure 1.2](#extract-fig) above for explanation).  

```{r gitlab-fig, echo = FALSE, eval = TRUE, fig.cap = "Pipelines can be downloaded directly from their GitLab website."}
knitr::include_graphics("figures/screenshot_download_gitlab.png")
```

_Command-line_   

Any member of the RIVM has a (RIVM-specific) GitLab account. You can log in with the same credentials that you use for accessing your workspaces. In the case of pipelines hosted on GitHub, you may need a free GitHub account.     

1.  Open the “terminal” (you could also open “terminator”) by going to the “Applications” menu of the linux environment.  

```{r commandline-fig, echo = FALSE, eval = TRUE, fig.cap = "Pipelines can be downloaded directly from their GitLab website."}
knitr::include_graphics("figures/schreenshot_terminal.png")
```

2. Go to the location where you want to download the pipeline using the command ‘cd’. For instance:  

```{bash, eval = FALSE}
cd /mnt/scratch_dir/<my_folder>/
```
**Note:** mind the slash at the beginning of the path

3. Download the pipeline using the `git clone` command  

```{bash, eval = FALSE}

git clone <url_to_the_pipeline>.git

```
**Note**: notice that I added ".git" to the URL of the pipeline.  

You will be asked to give your credentials (username + password) and then the (already unzipped) pipeline should have been downloaded in your current folder. 

### What to expect while running a Juno pipeline {#what-to-expect}  

The Juno pipelines usually run automated. Minimum input of the user is required. Detailed information on the required input can be found in the section for the specific pipeline. Sometimes a pipeline can ask for input from the user to agree on installing software or a database ([Figure 1.5](#installation-fig) step 1), if you get asked to give permission, please do so in order to run the pipeline. This is most often in the form of pressing y followed by enter ([Figure 1.5](#installation-fig) step 2).

The first time a Juno pipeline is executed, the preparation might take longer than expected. This is due to the installation of the basic software that is required for the pipeline to run. Be patient! You can recognize that the pipeline is still preparing when it shows a blinking box ([Figure 1.5](#installation-fig) step 3) or when it keeps printing lines inside the terminal. If the installation takes longer than 1 hour check the section [General Troubleshooting](#general-troubleshooting).

```{r installation-fig, echo = FALSE, eval = TRUE, fig.cap = "Screenshot of the Juno-typing pipeline in the terminal. The pipeline asks to create an environment(step 1). User input is required. To proceed the pipeline press y followed by enter. If executed correctly the pipeline will now show that it is creating the environment(step 2). The blinking box at the bottom indicates that the pipeline is still installing/updating(step 3)."}
knitr::include_graphics("figures/show_installation.png")
```

After installation the Juno pipeline will start running. Now the terminal shows <span style="color:#f4d03f;background:#2e3131;padding:5px">yellow</span> and/or <span style="color:#00b16a;background:#2e3131;padding:5px">green</span> messages. These messages indicate that the pipeline is being executed ([Figure 1.6](#snakemake-complete-run-fig)). At the start of the yellow messages the number of steps is shown ([Figure 1.6](#snakemake-complete-run-fig) step 1).  The amount of steps indicate the progress of the pipeline in %. Once the pipeline is finished there will be a message printed that all the steps are performed ([Figure 1.6](#snakemake-complete-run-fig) step 2).

```{r snakemake-complete-run-fig, echo = FALSE, eval = TRUE, fig.cap = "Screenshot of the Juno AMR pipeline in the terminal. The pipeline is executing all required jobs to create the requested results. The terminal shows a list of all the jobs that will be executed(step 1). Furthermore there is green and yellow text that shows the steps of the pipeline. At the bottom of the terminal there is a line that shows the pipeline is finished(step 2)."}
knitr::include_graphics("figures/snakemake_complete_run.png")
```

If a step fails, you will likely see <span style="color:#d64541;background:#2e3131;padding:5px">red</span> text appearing on the screen ([Figure 1.7](#snakemake-complete-run-fig)). The pipeline might proceed the other steps. If the pipeline fails check the section [General Troubleshooting](#general-troubleshooting) for more help or any other problems you may encounter.

```{r snakemake-error-fig, echo = FALSE, eval = TRUE, fig.cap = "Screenshot of the Juno AMR pipeline in the terminal. The pipeline failed on one of the steps. The red text shows an error message."}
knitr::include_graphics("figures/screenshot_snakemake_error.png")
```

**Note:** Do not keep all your data (including results) on the scratch_dir partition. You are allowed to keep 400GB max. With sequencing data, the storage space can get full quite fast.

### General output and log files for every pipeline {#general-output}  

The output of the Juno pipelines is divided over multiple folders inside the output folder. For each pipeline, there is an audit_trail folder, log folder, and result folder for each step or tool. The folders with results are probably the most interesting and contain most of the information you would use for analysis. The audit_trail folder contains information about the software, parameters, samples, and more. This kind of information can be useful for reproducibility or publications. The log folder contains information that is required for debugging and/or troubleshooting. For the developers, it is essential to have access to these files when an error occurs.  

All the output will be shortly discussed below. An example of an output folder is shown in [Figure 1.8](#snakemake-folder).

 - result folder(s)  
The `output` folder contains one result folder for each step that is performed by the pipeline. Inside the folder, there are results for each of the samples. The result output is different for each pipeline, you can check the pipeline's page or the tool that is used for more information about the output.

 - audit_trail folder  
The information in the `audit_trail` folder can be useful for the reproducibility of the pipeline and analysis.
     - The `log_conda.txt` file contains information about the software that was used to run the pipeline.
     - The `log_config.txt` enlists all parameters that were used to run the pipeline. 
     - The `log_git.txt` contains information about repositories or the code that was downloaded.
     - The `snakemake_report.html` contains an overview of all the steps that were performed with the samples in the input folder. It shows when the steps were performed, what output was produced, what software was used as well as some statistics about the run.  
     
 - log folder  
The `log/cluster/` or `log/drmaa/` folder contains .error and .out(log) files. For each step in the pipeline, there is one .error and one .out file. These files are useful to debug system/memory errors. If a step fails to perform and an error occurs, the .error file will show information about the error. The .out file contains information that is normally shown on the command line. This information can be originating from the tools that are used or from the pipeline itself. Sometimes these files can be empty, this happens if there were no problems or messages generated on the run or because the problem lies before the job/analysis was even started. You will need this output if you want to contact a developer when you run into problems. You can send the files or the location(example: `mnt/scratch-dir/mydirectory/output/log`) of the files when you contact the developer. 

**Note:** Do not delete the contents of the log folder.

```{r snakemake-folder, echo = FALSE, eval = TRUE, fig.cap = "Example of an output folder. 1 shows the audit_trail folder, 2 shows output folders per step or tool, 3 shows the log folder."}
knitr::include_graphics("figures/output_folder_example.png")
```
